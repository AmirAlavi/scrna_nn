#!/usr/bin/env python
"""Impute missing data

Usage:
    impute.py <expression_h5> [--threshold=<thresh> -k=<k> --consistency_check --database=<file>]
    impute.py (-h | --help)
    impute.py --version

Options:
    -h --help                         Show this screen.
    --version                         Show version.
    -t <thresh> --threshold=<thresh>  Missing value threshold. Float between 0
                                      and 1.0. Only keep cells with at most
                                      this percentage of missing data (genes).
                                      [default: 0.25]
    -k <k>                            Num neighbors for kNN-impute.
                                      [default: 10]
    -c --consistency_check            Determine if within a study there are
                                      genes that are not all NaNs. First,
                                      coerce the zeros in such columns to NaN.
    -d <file> --database=<file>       Database to use to calculate a global
                                      nearest neighbor distance matrix. If not
                                      specified, then the distance matrix is
                                      calculated for each study separately.
"""
#import pdb; pdb.set_trace()
import time
import multiprocessing
from itertools import repeat

import numpy as np
import pandas as pd
from docopt import docopt
from scipy.spatial.distance import pdist, squareform


def worker_print(worker_id, message):
    print("worker_id {:3d}: {}".format(worker_id, message), end='', flush=True)

def get_accessions_from_accessionSeries(accessionSeries_list):
    accessions = []
    for accessionSeries in accessionSeries_list:
        accession = accessionSeries.split('_')[0]
        accessions.append(accession)
    return np.array(accessions)

def load_data_from_h5(name):
    store = pd.HDFStore(name)
    df = store['rpkm']
    store.close()
    return df

def write_data_to_h5(name, df):
    store = pd.HDFStore(name)
    store['rpkm'] = df
    store.close()

def filter_cells(df, missing_threshold):
    """Remove cells that have more than a given threshold percentage of missing values
    """
    #df = df.drop_duplicates()
    nans = df.isnull().values
    print(nans.shape)
    num_genes = nans.shape[1]
    nan_percentages = nans.sum(axis=1) / num_genes
    to_keep = nan_percentages < missing_threshold
    print("Keeping  {:8} cells".format(to_keep.sum()))
    print("Filtered {:8} cells".format(np.logical_not(to_keep).sum()))
    return df.loc[to_keep]

def fill_with_median_expression(mat):
    # Doing this in pandas, provides convenient operations to fill NaNs
    #cell_medians = .median(axis=1)
    #filled = df.transpose().fillna(cell_medians).transpose()
    cell_medians = np.nanmedian(mat, axis=1)
    nan_inds = np.where(np.isnan(mat))
    mat[nan_inds] = np.take(cell_medians, indices=nan_inds[0])
    #return mat

def impute_for_study(study_df, worker_id, k, dist_mat=None):
    #global GLOBAL_DF
    t0 = time.time()
    #study_df = GLOBAL_DF.iloc[samples_in_study]
    worker_print(worker_id, "Shape of study subset: {}\n".format(study_df.shape))
    study_mat = study_df.values
    if dist_mat == None:
        study_filled = study_mat.copy()
        fill_with_median_expression(study_filled)
        dist_mat = squareform(pdist(study_filled.T))

    # modify dist_mat to have nans in columns of nan_genes
    nan_cols = np.unique(np.where(np.isnan(study_mat))[1])
    dist_mat[:, nan_cols] = np.nan
    nearest_genes = np.argsort(dist_mat, axis=1)
    dist_mat = np.sort(dist_mat, axis=1)
    nearest_genes = nearest_genes[:, :k]
    dist_mat = dist_mat[:, :k]

    for nan_col in nan_cols:
        study_mat[:, nan_col] = np.average(study_mat[:, nearest_genes[nan_col]], axis=1)
    study_df.iloc[:,:] = study_mat
    #assert(GLOBAL_DF.iloc[samples_in_study].isnull().values.any() == False)
    worker_print(worker_id, "impute for study took: {}\n".format(time.time()-t0))
    return study_df

def impute_missing_values(df, k, knn_data, ncpus):
    t0 = time.time()
    accessions = get_accessions_from_accessionSeries(df.index)
    accession_set = np.unique(accessions)
    print(str(len(accession_set)) + " studies to process.")
    study_indices = [accessions == accn for accn in accession_set]
    study_dfs = [df.iloc[study_idx] for study_idx in study_indices]
    worker_ids = list(range(len(accession_set)))
    with multiprocessing.Pool(processes=ncpus) as pool:
        # dispatch jobs
        print("Dispatching worker processes...")
        results = pool.starmap(impute_for_study, zip(study_dfs, worker_ids, repeat(k), repeat(knn_data)))
    imputed_df = pd.concat(results)
    assert(imputed_df.isnull().values.any() == False)
    print("Total impute time: ", time.time()-t0)
    return imputed_df

def make_nans_consistent(df, accn, samples_in_study):
    # Coerce any zeros in a column that has NaNs to also be NaNs
    study_df = df.iloc[samples_in_study]
    nan_genes = study_df.columns[study_df.isna().any()].tolist()
    df.loc[samples_in_study, nan_genes] = df.loc[samples_in_study, nan_genes].replace(0, np.nan)
    
def check_study_uniformity(df, accn, samples_in_study):
    study_df = df.iloc[samples_in_study]
    nan_genes = study_df.columns[study_df.isna().any()].tolist()
    inconsistent_genes = []
    for gene in nan_genes:
        if study_df[gene].isnull().sum() != study_df.shape[0]:
            inconsistent_genes.append(gene)
    if len(inconsistent_genes) > 0:
        print("Accn {} has {} cells, {} genes with nans, {} inconsistent genes!".format(accn, study_df.shape[0], len(nan_genes), len(inconsistent_genes)))
        #print(study_df[inconsistent_genes])
    else:
        print("Accn {} has {} cells, {} genes with nans".format(accn, study_df.shape[0], len(nan_genes)))
    
def consistency_check(df):
    accessions = get_accessions_from_accessionSeries(rpkm_df.index)
    for accn in np.unique(accessions):
        study_indicies = accessions==accn
        make_nans_consistent(df, accn, study_indicies)
        check_study_uniformity(df, accn, study_indicies)
        
if __name__ == '__main__':
    args = docopt(__doc__)
    ncpus = multiprocessing.cpu_count()-1
    print("Using " + str(ncpus) + " CPUs")
    
    rpkm_df = load_data_from_h5(args['<expression_h5>'])
    print(rpkm_df.shape)

    rpkm_df = filter_cells(rpkm_df, float(args['--threshold']))
    #accessions = get_accessions_from_accessionSeries(rpkm_df.index)

    if args['--consistency_check']:
        consistency_check(rpkm_df)
    
    t0 = time.time()
    knn_data = None
    if args['--database'] is not None:
        knn_data = args['--database']
    imputed = impute_missing_values(rpkm_df, int(args['-k']), knn_data, ncpus)
    assert(imputed.isnull().values.any() == False)
    print(imputed.shape)
    print("imputation took: ", time.time()-t0)
    write_data_to_h5("imputed.h5", imputed)
